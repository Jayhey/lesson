{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오늘 할 내용\n",
    "\n",
    "- cifar10 이미지 데이터를 사용한 모델링\n",
    "   - convolution layer (cnn : 합성곱 신경망)\n",
    "   - 직접 모델링 & 학습 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 손쉬운 변환법\n",
    "# batch_size : 몇 개의 데이터를 한 번에 태울 것인가? (참고 : 밑바닥 딥러닝, p.115, p.239)\n",
    "# shuffle : 비복원 추출 여부 (구슬을 주머니에서 꺼낼 것인가?)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_sampler.sampler.data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # numpy array를 그림으로 바꿔주는 함수\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "for i in range(5):    \n",
    "    imshow(trainset.data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3개의 input chnnel, 6개의 convolution filter, 5x5의 kernel size\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=6,\n",
    "                               kernel_size=5) # 이 표현식과 같음 : kernel_size=(5,5)\n",
    "        # 2 x 2 max pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # input 6, output 16\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*6*6, 100)\n",
    "        self.fc2 = nn.Linear(100, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 마지막 레이어에선 activation function을 넣지 않음\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크가 어떻게 진행되는지 하나씩 실행해보기\n",
    "- .size()를 통해서 어떤 방식으로 dimension이 변화하는지 check\n",
    "- cifar10 network\n",
    "![image](https://miro.medium.com/max/3294/1*vkQ0hXDaQv57sALXAJquxA.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainset.data[:4]\n",
    "\n",
    "print(x.shape)\n",
    "# plt.imshow(x)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch의 경우 (batch_size, channel, width, height) 순서를 가짐\n",
    "# batch size를 맞춰주기 위해 앞에 1로 reshape\n",
    "x = x.reshape(-1, 3, 32, 32)\n",
    "\n",
    "# numpy를 torch tensor로 변환\n",
    "x = torch.tensor(x).float()\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB 3 channel이 input으로 들어옴\n",
    "# out_channels : 몇 개의 채널로 나갈 것인가?\n",
    "# kernel_size : 가로, 세로 크기?\n",
    "conv1 = nn.Conv2d(in_channels=3,\n",
    "                  out_channels=6,\n",
    "                  kernel_size=5)\n",
    "conv1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = conv1(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling : 이미지의 차원 축소 (밑바닥 딥러닝, p.240)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(6, 16, 3)\n",
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = conv2(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뒷 채널과 맞춰주기 위한 reshape\n",
    "# Flatten\n",
    "x = x.view(-1, 16*6*6)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(16*6*6, 100)\n",
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc1(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fc2 = nn.Linear(100, 60)\n",
    "fc3 = nn.Linear(60, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc2(x)\n",
    "x = fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 만든 network에 데이터 태우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = trainset.data[:4]\n",
    "\n",
    "test.shape\n",
    "\n",
    "test = test.reshape(-1, 3, 32, 32)\n",
    "test = torch.tensor(test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = net(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 교차엔트로피 오차 (밑바닥 딥러닝 p.113)\n",
    "# 어떤 손실 함수를 쓸 것인가?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD : Stochastic Gradient Descent\n",
    "# 어떤 방식으로 파라미터를 학습할 것인가? (밑바닥 딥러닝 p.189 읽어보기)\n",
    "# lr = learning rate (밑바닥 딥러닝 p.131)\n",
    "# 학습 도중에 loss가 너무 튀거나 너무 적게 움직이면 조절해볼 수 있음\n",
    "# https://copycode.tistory.com/166\n",
    "\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa377ca7a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000] loss : 2.3027240235805513\n",
      "[2000] loss : 2.300682072877884\n",
      "[3000] loss : 2.29876478433609\n",
      "[4000] loss : 2.2957096543312074\n",
      "[5000] loss : 2.2921512386798857\n",
      "[6000] loss : 2.284779597759247\n",
      "[7000] loss : 2.271058345556259\n",
      "[8000] loss : 2.248588036894798\n",
      "[9000] loss : 2.198488947272301\n",
      "[10000] loss : 2.1421441687345504\n",
      "[11000] loss : 2.1028348878622056\n",
      "[12000] loss : 2.063841153383255\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs, labels = data\n",
    "    \n",
    "    # 매번 iteration마다 gradient 초기화\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # loss 계산 (cross entropy loss)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # 학습해야하는 모든 parameter들의 gradient 계산\n",
    "    loss.backward()\n",
    "    # backpropagation 진행 (파라미터 업데이트)\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    if i % 1000 == 999:\n",
    "        print(f'[{i+1}] loss : {running_loss / 1000}')\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(trainloader):\n",
    "    if i == 0:\n",
    "        inputs, labels = data\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0510, -0.1922, -0.0588,  ...,  0.3333, -0.0275,  0.0588],\n",
       "         [-0.0510, -0.4510, -0.4118,  ...,  0.0667, -0.0431, -0.0667],\n",
       "         [-0.3804, -0.7490, -0.7020,  ..., -0.1137,  0.3020, -0.0353],\n",
       "         ...,\n",
       "         [ 0.1765,  0.2784,  0.2784,  ..., -0.2157, -0.3098, -0.2471],\n",
       "         [ 0.2706,  0.3647,  0.3255,  ...,  0.0667, -0.0196, -0.1922],\n",
       "         [ 0.3412,  0.3176,  0.2784,  ...,  0.2314, -0.0196, -0.0667]],\n",
       "\n",
       "        [[ 0.2549,  0.0118,  0.1373,  ...,  0.3569,  0.2392,  0.3569],\n",
       "         [ 0.0745, -0.4431, -0.3961,  ...,  0.0039,  0.1451,  0.2627],\n",
       "         [-0.3569, -0.7490, -0.7098,  ..., -0.0824,  0.3333,  0.2314],\n",
       "         ...,\n",
       "         [ 0.4510,  0.5059,  0.4980,  ..., -0.3098, -0.4196, -0.3490],\n",
       "         [ 0.4980,  0.5686,  0.5216,  ..., -0.0824, -0.1686, -0.3569],\n",
       "         [ 0.4980,  0.5137,  0.4745,  ...,  0.1216, -0.1922, -0.1843]],\n",
       "\n",
       "        [[-0.1843, -0.4667, -0.2471,  ...,  0.0667, -0.4588, -0.3804],\n",
       "         [-0.3098, -0.7098, -0.5451,  ..., -0.1373, -0.3804, -0.4824],\n",
       "         [-0.6471, -0.8902, -0.8353,  ..., -0.2000,  0.0902, -0.3961],\n",
       "         ...,\n",
       "         [-0.0588,  0.0745,  0.0902,  ..., -0.3569, -0.4745, -0.4510],\n",
       "         [ 0.0588,  0.1765,  0.1373,  ..., -0.1059, -0.2314, -0.4353],\n",
       "         [ 0.1765,  0.1294,  0.0902,  ..., -0.0431, -0.3020, -0.3020]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0152, -0.0907, -0.0668, -0.0836, -0.0629, -0.0522, -0.1290, -0.1026,\n",
       "         -0.0321, -0.0910],\n",
       "        [ 0.0245, -0.0798, -0.0692, -0.0951, -0.0696, -0.0477, -0.1089, -0.1036,\n",
       "         -0.0227, -0.0878],\n",
       "        [ 0.0169, -0.0786, -0.0664, -0.0889, -0.0648, -0.0409, -0.1148, -0.0943,\n",
       "         -0.0288, -0.0820],\n",
       "        [ 0.0094, -0.0960, -0.0595, -0.0872, -0.0694, -0.0488, -0.1341, -0.0977,\n",
       "         -0.0376, -0.0955]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = net(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4, 4, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3253, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(outputs, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

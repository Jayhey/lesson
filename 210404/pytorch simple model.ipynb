{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치의 기본적인 모델 flow 구조\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # 사용할 파라미터를 정의함 (neural net, convnet, lstm, 등등)\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # nn.Linear : 일반적인 뉴럴 네트워크\n",
    "        self.fc1 = nn.Linear(20, 30)\n",
    "        self.fc2 = nn.Linear(30, 40)\n",
    "        self.fc3 = nn.Linear(40, 10)\n",
    "        \n",
    "    # 실제로 값이 통과하는 부분 (연산 작업들은 forward에서 진행)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=20, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=40, bias=True)\n",
       "  (fc3): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 파악\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 8.7892e-02, -1.1548e-01,  1.6620e-01, -1.7928e-01, -1.3067e-01,\n",
       "                        6.1698e-02, -1.0608e-01,  1.5505e-01,  1.1229e-01,  4.0509e-02,\n",
       "                       -2.1093e-02,  1.8888e-01, -2.1567e-01, -4.6398e-02,  1.9795e-02,\n",
       "                        4.3206e-02,  1.8654e-01,  1.1400e-01,  2.2060e-01,  1.2072e-01],\n",
       "                      [-1.8755e-01, -1.0279e-01, -2.1753e-01,  1.3323e-01, -4.5611e-02,\n",
       "                       -5.7762e-02, -5.1718e-02, -1.7470e-01,  4.4402e-02, -3.4107e-02,\n",
       "                        1.8209e-01, -9.5874e-02,  5.6981e-03, -1.3616e-02, -6.9460e-02,\n",
       "                        1.8790e-02, -8.9170e-02,  6.5433e-03, -1.5179e-01,  2.7733e-03],\n",
       "                      [ 6.6114e-02, -1.2940e-02,  1.3772e-01,  1.1761e-01, -1.9706e-01,\n",
       "                        1.0238e-01, -3.3200e-02,  3.3774e-02,  1.3501e-01,  8.6705e-02,\n",
       "                        9.0084e-02, -1.7990e-01, -1.7097e-02,  2.2267e-01,  9.9010e-03,\n",
       "                       -2.4665e-02, -1.5812e-02,  8.1859e-02,  4.3157e-02,  1.1177e-01],\n",
       "                      [-7.0392e-03, -2.0201e-01, -4.9963e-02, -1.8813e-02,  6.6440e-02,\n",
       "                       -2.9254e-02, -1.8138e-01,  1.2072e-01, -5.1801e-03, -1.3401e-01,\n",
       "                        1.2218e-02, -3.1814e-02, -4.5054e-02,  7.1794e-02, -1.7934e-01,\n",
       "                       -1.6761e-02,  1.8158e-01,  1.5481e-01, -1.6375e-01,  1.9185e-01],\n",
       "                      [ 8.4411e-02,  2.2416e-02,  2.1286e-01, -1.4156e-01,  1.2340e-04,\n",
       "                        5.8742e-02,  4.1267e-02, -1.8047e-01, -1.8327e-02, -8.8876e-02,\n",
       "                       -1.0542e-01,  3.4651e-02, -1.6053e-01, -1.2899e-01, -3.0351e-02,\n",
       "                       -1.3241e-01, -8.9433e-02, -5.2070e-02,  5.3779e-02,  1.6128e-01],\n",
       "                      [-1.1075e-01,  2.0959e-01, -1.8813e-01,  2.3702e-02,  1.6216e-01,\n",
       "                       -7.1539e-02,  1.2252e-01,  9.9243e-02,  5.6855e-02, -5.9500e-02,\n",
       "                        2.0120e-01, -1.6173e-01,  8.2812e-04, -1.8495e-01, -2.0277e-01,\n",
       "                       -3.1459e-02,  5.6386e-02,  1.2471e-01, -1.6334e-01, -9.7102e-02],\n",
       "                      [-1.2747e-01, -1.7555e-01, -1.9442e-01,  6.6351e-02,  8.7858e-02,\n",
       "                       -1.4711e-01,  1.9157e-01,  6.3169e-04, -9.1377e-02, -2.0972e-01,\n",
       "                       -7.5722e-02, -1.4421e-01, -1.3991e-01,  1.4374e-02,  6.5707e-02,\n",
       "                        2.7599e-02, -2.0712e-01,  1.6984e-01,  1.9345e-01,  5.0062e-02],\n",
       "                      [-1.7014e-01, -1.1697e-01, -2.1598e-01,  6.7702e-02,  2.0633e-01,\n",
       "                       -1.4926e-02, -1.1948e-01, -1.3053e-01, -2.2153e-02,  1.1520e-02,\n",
       "                       -1.9275e-01,  1.0429e-01, -6.6099e-02, -1.8077e-01,  8.1474e-02,\n",
       "                        1.2199e-01,  6.9332e-02,  2.3928e-02,  1.9610e-01,  1.5614e-01],\n",
       "                      [ 9.0505e-02, -5.8793e-02, -1.1299e-01,  9.2296e-02, -2.2300e-01,\n",
       "                        6.4232e-02,  9.9102e-02,  3.6236e-03, -1.3365e-01,  1.8697e-03,\n",
       "                        1.2639e-01, -9.9898e-02, -9.2541e-02, -2.2012e-01, -1.1354e-01,\n",
       "                       -3.3662e-02,  9.1214e-02, -1.2968e-01,  7.7569e-02, -4.4388e-02],\n",
       "                      [ 1.6960e-01,  5.7033e-02,  7.9250e-02,  1.2994e-01,  1.9509e-01,\n",
       "                       -2.0871e-01, -2.3945e-02,  1.0988e-01, -1.3342e-01,  2.0270e-01,\n",
       "                        2.0099e-01, -5.3117e-02, -1.4841e-01,  2.1243e-01,  1.4372e-01,\n",
       "                        2.0107e-01,  1.2495e-01, -1.8257e-01, -5.6933e-02,  2.2728e-02],\n",
       "                      [ 1.8966e-01, -6.5853e-02, -6.7237e-02, -3.4954e-02,  5.0544e-02,\n",
       "                        3.4504e-02,  1.6334e-01, -1.3939e-01, -1.6198e-01, -1.5049e-01,\n",
       "                       -1.5121e-01,  1.1334e-03,  1.2222e-01, -1.5664e-01, -1.4026e-01,\n",
       "                        5.3032e-03,  1.4320e-01, -2.0879e-01, -4.9912e-02,  4.8592e-02],\n",
       "                      [-9.9056e-02, -1.1014e-02,  1.2772e-02, -3.6483e-02, -1.8365e-01,\n",
       "                       -1.2710e-01, -2.3382e-02, -5.4361e-02, -1.8322e-03, -1.9167e-01,\n",
       "                       -8.2609e-03,  4.2538e-03, -1.7087e-01,  1.7524e-01, -2.3404e-02,\n",
       "                       -2.1443e-01,  4.0768e-02, -2.0646e-01,  5.1991e-02,  1.4559e-01],\n",
       "                      [ 2.0411e-01,  1.4191e-01, -1.6624e-01,  3.7023e-02, -1.1318e-01,\n",
       "                        1.4702e-01,  1.1885e-01, -8.4230e-02,  8.6990e-02, -2.0496e-02,\n",
       "                       -1.5544e-01, -2.1907e-01,  6.6847e-02,  1.9530e-02,  1.6105e-01,\n",
       "                        9.5506e-02, -1.0950e-02, -1.6325e-01, -1.9642e-01,  7.5165e-02],\n",
       "                      [-2.1010e-01,  1.7322e-01, -8.2447e-02,  1.9653e-01, -1.8443e-01,\n",
       "                        1.4775e-01, -1.2036e-01, -2.1409e-01,  1.2719e-01, -1.4363e-01,\n",
       "                        1.2891e-01, -1.7641e-01, -1.3942e-02,  1.8480e-02,  7.9612e-02,\n",
       "                       -2.0315e-01,  1.1319e-01, -8.3593e-02, -2.0790e-01, -1.0801e-01],\n",
       "                      [-2.1889e-01, -6.6403e-03,  1.3730e-01,  1.6630e-01,  6.0290e-02,\n",
       "                       -1.8749e-01,  1.1444e-01, -2.1893e-01, -1.8934e-01, -6.3026e-02,\n",
       "                       -6.0714e-02, -2.4672e-02, -3.7893e-02, -1.6448e-01, -2.1183e-01,\n",
       "                       -1.0103e-02, -1.4558e-03, -6.9079e-02,  6.8663e-02, -1.8851e-01],\n",
       "                      [ 1.4029e-01,  1.8551e-01,  1.2740e-01, -1.6228e-01,  1.5640e-01,\n",
       "                        5.7792e-02, -5.3744e-02, -1.1692e-01, -1.5589e-03, -1.9322e-01,\n",
       "                        1.4419e-01,  8.4379e-03, -1.2656e-01,  1.0333e-01, -1.0819e-02,\n",
       "                        1.9430e-01, -1.1572e-02,  1.5341e-01, -1.2194e-02, -1.6853e-01],\n",
       "                      [-1.7480e-01,  1.6666e-01,  1.0362e-01,  9.8178e-02, -4.1181e-02,\n",
       "                        2.1044e-01, -3.0667e-02, -9.7015e-02, -3.2150e-02, -1.4660e-01,\n",
       "                       -1.7535e-01, -1.4213e-01,  9.9851e-02, -1.3667e-01,  2.1164e-01,\n",
       "                       -1.4109e-01,  2.1684e-01,  6.0425e-03, -1.1735e-02,  5.3176e-03],\n",
       "                      [ 1.8172e-01, -1.2875e-01, -1.0169e-01,  1.7797e-01, -1.5695e-01,\n",
       "                        1.9064e-01, -2.0753e-01, -1.9614e-01,  5.4095e-02,  2.1170e-01,\n",
       "                       -4.6017e-02,  1.0543e-01, -7.3406e-03,  7.7641e-03, -1.6198e-02,\n",
       "                       -3.9878e-02, -1.8584e-01, -1.1975e-01,  5.1605e-02,  2.2035e-01],\n",
       "                      [ 2.1330e-01, -1.8142e-01,  1.0390e-01,  1.5065e-01,  7.8291e-02,\n",
       "                       -1.5478e-01,  3.4093e-02,  1.1223e-01,  8.2401e-02, -1.6230e-01,\n",
       "                        1.3584e-01,  1.2872e-02,  4.5339e-03, -8.7732e-02, -6.2586e-02,\n",
       "                        2.8474e-02,  1.1094e-01,  4.1722e-03,  8.3658e-02,  1.8548e-01],\n",
       "                      [ 1.7686e-01,  7.2482e-03,  8.3827e-02,  1.2578e-01, -3.7768e-02,\n",
       "                       -8.7159e-02,  2.1405e-01, -1.1848e-01, -1.7704e-01,  8.4654e-02,\n",
       "                       -1.4325e-01,  1.5209e-01, -6.4837e-02,  2.2152e-01, -3.4516e-02,\n",
       "                        1.9827e-01,  5.4777e-02,  7.7886e-02,  8.1417e-02, -5.1379e-02],\n",
       "                      [-1.3937e-01,  2.1106e-01, -2.1444e-01,  5.0597e-02,  2.0286e-01,\n",
       "                       -1.9579e-02, -1.7852e-01,  2.1823e-01,  4.7615e-02, -9.0530e-02,\n",
       "                       -2.1951e-01, -1.2435e-01, -1.3686e-01, -1.1212e-01,  8.6987e-02,\n",
       "                       -1.3078e-01,  1.6560e-01, -2.0967e-01,  1.5400e-01, -4.3159e-02],\n",
       "                      [ 1.3897e-01,  1.1182e-02, -1.6942e-01, -1.7008e-01, -1.4563e-01,\n",
       "                        1.8811e-01, -1.3168e-01, -7.8665e-02, -9.0442e-02, -5.8551e-02,\n",
       "                       -1.5918e-01,  2.2241e-01,  1.9930e-01,  2.1200e-01, -2.0026e-01,\n",
       "                        1.9002e-01, -4.5455e-02,  1.7494e-01,  2.0806e-01,  1.9730e-01],\n",
       "                      [ 8.2661e-02, -1.1122e-01, -7.1048e-02,  6.6938e-02,  7.9741e-02,\n",
       "                       -7.3310e-02, -3.0089e-02,  1.4161e-01,  2.1648e-02,  2.1962e-01,\n",
       "                       -9.0421e-02,  6.4320e-03, -1.1260e-01,  4.9190e-02,  1.8385e-01,\n",
       "                       -1.0326e-01, -7.6146e-02, -2.1235e-01, -1.4270e-02,  1.7104e-01],\n",
       "                      [ 2.8078e-02, -1.0718e-01, -1.7511e-01,  1.7521e-01,  5.5897e-02,\n",
       "                       -2.1206e-01,  8.9143e-02,  4.7298e-02, -1.3145e-01,  1.2959e-01,\n",
       "                        1.1678e-01,  3.0959e-02, -8.3715e-02,  1.6220e-01, -7.1623e-02,\n",
       "                       -9.1502e-02,  8.9370e-02,  5.3532e-02,  9.5522e-02, -1.4198e-01],\n",
       "                      [-1.5790e-01,  1.8443e-01,  4.2237e-02, -1.7408e-01,  1.2289e-01,\n",
       "                       -1.9227e-01, -4.2324e-03, -1.8888e-01,  4.6531e-02, -1.7091e-01,\n",
       "                       -8.2357e-02,  1.3484e-01,  1.2271e-01, -1.9835e-01,  2.0956e-01,\n",
       "                        7.1364e-02, -1.0616e-01,  2.0024e-01,  1.7652e-02,  7.5582e-02],\n",
       "                      [ 2.1976e-01,  1.3518e-01, -2.9523e-02,  3.1172e-02,  7.0135e-02,\n",
       "                        1.3431e-01,  6.9176e-04,  9.8628e-02,  9.1380e-02, -8.2064e-02,\n",
       "                       -1.8594e-01, -6.6951e-02, -1.0524e-01,  7.2321e-02,  1.0029e-01,\n",
       "                        1.4853e-01, -8.9509e-02, -2.7416e-02, -8.1998e-02, -8.4014e-02],\n",
       "                      [-9.3348e-02,  1.1877e-01, -9.4433e-02, -1.0897e-01,  1.4411e-01,\n",
       "                        1.3860e-01, -1.7655e-02,  1.2400e-02, -4.8403e-03, -1.2509e-01,\n",
       "                        7.0781e-02,  1.1781e-02,  1.2526e-01,  3.2273e-02,  2.1433e-01,\n",
       "                        1.3548e-01, -1.5030e-01, -1.1246e-01,  1.2691e-01,  2.9416e-02],\n",
       "                      [ 1.5515e-01, -1.8284e-01,  1.2649e-02, -2.0031e-01, -1.1309e-01,\n",
       "                        1.1425e-01, -9.7618e-02, -8.1467e-02, -1.3377e-01,  6.9051e-02,\n",
       "                       -1.0344e-01,  2.1088e-01,  1.5739e-01,  6.9839e-02, -3.2265e-02,\n",
       "                        1.0251e-01,  1.3242e-01,  1.1896e-01, -1.1507e-01,  1.3041e-01],\n",
       "                      [ 4.1192e-02,  2.9482e-02,  1.1734e-02, -1.2766e-01,  2.0701e-01,\n",
       "                       -6.7305e-02,  2.2341e-01,  6.9071e-02, -1.5374e-01, -2.9146e-02,\n",
       "                        7.6002e-02, -1.7748e-01, -4.8508e-02, -4.2524e-02,  1.9027e-01,\n",
       "                        1.9025e-01,  1.7275e-01, -1.7107e-01, -3.8273e-02, -8.8604e-02],\n",
       "                      [ 1.6212e-01, -3.5726e-02, -1.1790e-02, -3.5904e-03, -8.8688e-02,\n",
       "                        1.4329e-01,  1.6492e-01,  1.7394e-01, -5.2904e-02, -1.3823e-01,\n",
       "                       -4.5540e-02, -2.0025e-02,  1.0449e-01, -6.1346e-02, -1.7596e-01,\n",
       "                        5.6046e-02, -1.2832e-01, -1.7185e-01,  5.6628e-02, -1.0116e-01]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0805,  0.2042,  0.0418, -0.0225,  0.0126, -0.1038, -0.2146, -0.1344,\n",
       "                       0.1217, -0.1480,  0.0349,  0.0772,  0.0432,  0.0600, -0.1922,  0.1040,\n",
       "                      -0.1197,  0.1282, -0.0736,  0.1910,  0.0270, -0.0939,  0.0148,  0.2061,\n",
       "                      -0.0882, -0.1909, -0.2075,  0.0847, -0.0378, -0.0745])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.1629, -0.1386,  0.1082,  ...,  0.1545, -0.1737, -0.1357],\n",
       "                      [ 0.1373, -0.1653,  0.0517,  ..., -0.0298,  0.0395,  0.0793],\n",
       "                      [-0.1164,  0.1132, -0.1077,  ..., -0.0966,  0.1355, -0.0122],\n",
       "                      ...,\n",
       "                      [-0.0864,  0.0792, -0.1520,  ...,  0.0952,  0.0399, -0.0667],\n",
       "                      [ 0.0643,  0.0961, -0.0610,  ...,  0.0293,  0.0400, -0.1624],\n",
       "                      [-0.0423, -0.1218, -0.0225,  ...,  0.1723,  0.0770, -0.1423]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0637,  0.0372, -0.0339,  0.1013,  0.0869, -0.1566, -0.0898, -0.0415,\n",
       "                       0.0198,  0.1563, -0.1212, -0.0617, -0.1480, -0.1749, -0.0605,  0.1228,\n",
       "                      -0.0928,  0.0880,  0.0636,  0.0228, -0.0657, -0.1821, -0.0864, -0.0419,\n",
       "                      -0.1334,  0.0857,  0.1460, -0.0984,  0.0103, -0.0347, -0.0203, -0.1127,\n",
       "                       0.0909, -0.1719, -0.1669,  0.0778, -0.1328,  0.0889, -0.0621, -0.0930])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-1.2887e-01,  7.4299e-02, -8.1654e-02, -1.0541e-01,  2.6095e-02,\n",
       "                        5.5445e-03,  4.8036e-02,  5.7169e-02, -7.9449e-02,  1.3833e-02,\n",
       "                        1.0408e-01,  4.0326e-02,  9.8456e-03,  9.3005e-02,  7.7645e-02,\n",
       "                       -1.2942e-01, -3.2904e-02, -1.7109e-02,  7.6905e-02, -3.5224e-02,\n",
       "                        8.5569e-02, -1.3661e-01, -7.1185e-02, -6.6702e-02,  7.3340e-03,\n",
       "                       -1.2598e-01, -5.3712e-02, -1.0969e-01,  4.1290e-02,  4.7647e-02,\n",
       "                       -1.3376e-01,  9.4678e-02,  4.1431e-02, -1.4966e-01,  1.0390e-01,\n",
       "                        2.0194e-02,  7.2801e-02,  2.6917e-02, -8.6940e-02,  9.9204e-02],\n",
       "                      [-8.7724e-02, -2.5142e-02,  3.3498e-02, -1.3468e-01,  1.4583e-01,\n",
       "                       -6.7779e-02,  9.9110e-03, -8.8980e-02, -9.9128e-02, -1.4541e-01,\n",
       "                        2.2622e-02,  1.5543e-01, -7.3525e-02, -4.9659e-02,  1.3071e-01,\n",
       "                        1.3463e-01,  7.5033e-02,  1.5182e-01,  1.0258e-01, -1.7572e-02,\n",
       "                        1.0692e-01, -1.2312e-01, -3.5537e-02, -9.1553e-02, -1.4482e-01,\n",
       "                        1.8632e-02, -6.1893e-02, -7.9875e-02, -1.5670e-01,  5.9535e-02,\n",
       "                        1.2396e-02,  3.3768e-02,  9.6364e-02,  5.8024e-02,  1.1190e-02,\n",
       "                       -2.1138e-02,  1.4420e-01, -1.2196e-01, -1.0136e-01, -7.6377e-02],\n",
       "                      [ 1.1216e-01, -9.2229e-02, -2.7135e-02, -1.2209e-01,  1.0545e-01,\n",
       "                       -4.2047e-02, -2.1895e-02, -1.1525e-01,  1.1239e-02, -4.4611e-02,\n",
       "                       -3.8981e-02, -1.0232e-01, -3.9044e-02, -9.4720e-02, -1.2487e-01,\n",
       "                        3.8324e-02, -1.6384e-02,  1.0317e-01, -3.9829e-02, -5.5146e-03,\n",
       "                       -1.4707e-01,  1.0536e-01, -1.0299e-01,  1.4072e-01,  6.4648e-03,\n",
       "                        7.1790e-02,  5.1809e-02,  9.3440e-02, -1.1123e-01, -1.0354e-01,\n",
       "                       -2.0838e-02, -1.0357e-01, -7.7907e-02, -5.9725e-02,  1.5785e-02,\n",
       "                       -1.0705e-01,  1.1264e-01,  1.2537e-01, -1.4041e-01,  1.4740e-01],\n",
       "                      [ 3.5027e-02, -8.0048e-02, -9.2478e-02,  7.4499e-02,  8.6856e-02,\n",
       "                       -1.4631e-01, -6.0247e-02, -6.2574e-02, -1.5545e-01, -9.7818e-02,\n",
       "                       -1.3136e-01, -1.5058e-02,  2.2243e-02, -4.1725e-02,  7.4939e-02,\n",
       "                        7.6180e-02, -4.7823e-02,  7.4406e-02,  1.4024e-01, -7.3300e-02,\n",
       "                        1.4606e-01, -1.1066e-01, -1.1552e-01, -1.5804e-01, -8.6925e-02,\n",
       "                        7.2050e-02,  8.9709e-03, -8.0152e-02,  3.7430e-02,  9.6642e-02,\n",
       "                        7.6918e-02, -2.9893e-02,  4.9102e-02,  1.4476e-02,  4.6587e-02,\n",
       "                       -1.1690e-01,  6.7207e-02,  6.4639e-02,  1.9376e-02,  1.4185e-01],\n",
       "                      [-6.4422e-02, -1.2355e-01, -9.6885e-02,  1.4472e-01,  2.6864e-03,\n",
       "                        1.3930e-01,  1.0062e-01,  9.1713e-02, -8.3682e-03, -4.4252e-02,\n",
       "                        1.5333e-01, -1.3461e-01, -1.4444e-01,  8.5050e-02,  6.5651e-02,\n",
       "                       -1.0741e-01, -1.1416e-01, -3.9800e-03, -1.5370e-01,  5.7827e-02,\n",
       "                       -1.3507e-01, -1.8799e-02, -3.6294e-02,  2.2700e-02,  1.3618e-01,\n",
       "                       -1.3470e-01, -1.6700e-02, -9.0100e-02, -1.1910e-01, -9.2639e-02,\n",
       "                       -1.1758e-01,  1.3515e-01, -2.5796e-02,  1.1825e-03,  6.4629e-02,\n",
       "                        6.0194e-03,  8.9949e-02, -1.5689e-01,  1.2810e-01,  2.6662e-02],\n",
       "                      [-7.5157e-02, -1.3534e-01, -9.9346e-02,  1.8196e-03, -5.8921e-02,\n",
       "                       -4.6168e-02,  1.1840e-01, -1.0026e-01,  1.9184e-02, -8.4408e-02,\n",
       "                        1.1674e-01, -4.8083e-02,  2.3046e-02, -2.6975e-03,  1.4373e-01,\n",
       "                       -9.6424e-02, -1.4251e-02,  5.1280e-03,  8.9533e-02,  4.3308e-02,\n",
       "                       -7.9925e-02,  4.7412e-02, -5.6129e-02,  2.2867e-02, -1.3754e-01,\n",
       "                       -1.0856e-01,  1.1250e-01, -1.2378e-01,  7.5375e-02,  1.4934e-01,\n",
       "                        1.5584e-01,  5.8425e-02,  4.5495e-02, -8.5786e-05, -4.5234e-02,\n",
       "                       -1.0966e-01, -1.0688e-01, -1.3134e-01,  7.5045e-02, -6.3756e-02],\n",
       "                      [ 1.6634e-02,  7.3687e-02, -1.2175e-01,  1.3758e-01,  6.9084e-02,\n",
       "                       -3.3218e-02, -2.6000e-02,  5.5938e-02, -1.1720e-01,  5.7112e-02,\n",
       "                       -7.4525e-02, -1.9666e-02,  1.0310e-01, -2.7010e-02, -1.5507e-01,\n",
       "                        3.7080e-03, -1.5012e-01,  1.3062e-01, -5.6603e-02, -1.8645e-02,\n",
       "                       -1.5756e-02, -1.3671e-01, -1.1226e-02,  5.6733e-02, -1.3080e-02,\n",
       "                       -6.7749e-02,  9.2280e-03,  1.9879e-02,  9.5573e-02,  1.4616e-01,\n",
       "                        4.0516e-02,  9.0588e-02, -3.5471e-02,  1.1496e-01, -1.4678e-01,\n",
       "                       -4.9377e-02,  7.1649e-02, -1.0227e-01, -6.3330e-02,  5.5636e-02],\n",
       "                      [ 1.1040e-01,  7.5514e-02,  4.8817e-03, -1.1038e-01, -1.0349e-01,\n",
       "                        9.3532e-02, -7.1021e-02,  6.8528e-02, -1.2763e-01,  7.3507e-02,\n",
       "                       -1.2721e-01, -1.2694e-01,  3.1786e-02,  6.8746e-02,  1.4025e-01,\n",
       "                       -4.5087e-02,  4.3323e-03, -5.6773e-02,  1.1142e-01, -1.0657e-01,\n",
       "                       -3.2326e-02,  1.3943e-01, -7.3485e-02, -1.0655e-01, -1.8927e-02,\n",
       "                       -1.1471e-01, -6.0022e-02,  2.9498e-03,  8.8356e-02,  4.0149e-02,\n",
       "                        4.8540e-02, -1.4849e-01, -1.4174e-01,  1.2405e-01,  1.2608e-01,\n",
       "                       -9.2451e-02,  1.0256e-01, -4.8004e-02, -1.2769e-01, -1.2247e-02],\n",
       "                      [ 9.0679e-02, -3.6312e-02, -5.7241e-02, -1.2067e-01, -1.8416e-03,\n",
       "                       -1.1739e-01, -4.9478e-02, -6.8028e-02, -1.4358e-01,  3.4132e-02,\n",
       "                       -7.4104e-02,  1.0387e-01,  5.4889e-02, -6.3760e-02,  9.8181e-02,\n",
       "                       -1.7454e-02,  9.5052e-02,  3.1421e-02,  1.0513e-01,  7.9365e-02,\n",
       "                        4.0987e-02, -3.0903e-02,  3.7327e-02, -1.4285e-01,  1.0435e-01,\n",
       "                        7.6459e-02, -5.4266e-02,  1.1721e-01, -2.8284e-02, -2.7065e-02,\n",
       "                       -3.0899e-02, -9.6480e-02,  2.7756e-02,  1.2513e-02, -2.1235e-02,\n",
       "                       -7.3490e-02, -2.6146e-02, -2.4308e-02, -7.5796e-02,  1.3150e-01],\n",
       "                      [ 1.2648e-01,  1.4838e-01, -1.0990e-01, -9.3783e-02, -4.0330e-02,\n",
       "                        1.3533e-01, -1.2464e-01,  4.7431e-03, -2.1205e-02, -1.6756e-02,\n",
       "                       -4.3762e-02,  1.4927e-01,  1.2760e-01, -8.7891e-02, -1.1396e-01,\n",
       "                        1.9643e-02, -9.1374e-02, -5.4703e-02, -6.5238e-02,  1.1053e-01,\n",
       "                       -1.0106e-01, -1.0553e-01, -3.6263e-02, -8.6830e-02, -3.6690e-02,\n",
       "                       -5.4083e-02, -8.7069e-02,  4.9183e-02, -1.1998e-01, -1.0009e-01,\n",
       "                       -1.5402e-02, -1.1515e-01, -7.3497e-02,  1.2018e-01,  1.4858e-01,\n",
       "                        7.1416e-03,  1.0171e-01, -3.4623e-02,  7.0076e-02,  1.5445e-01]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.0824,  0.0101,  0.0927, -0.1498, -0.0579, -0.1505, -0.1303,  0.1536,\n",
       "                      -0.0744,  0.0230]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 직접 보기\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension size check하는 방법 (굉장히 많이 씀)\n",
    "net.state_dict()['fc2.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0989, -0.7890, -0.3475,  0.7860,  0.3738, -0.0164, -1.1611, -0.6929,\n",
       "          2.3368, -0.5923,  1.8013, -0.6683, -0.7019,  0.6226, -0.3736,  1.4655,\n",
       "         -0.2500, -0.0054, -0.2343, -0.2328]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 앞의 숫자는 batch size\n",
    "\n",
    "input_x = torch.randn(1, 20)\n",
    "input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1353,  0.0249,  0.2638, -0.1311, -0.0874, -0.2253, -0.0799,  0.0503,\n",
       "         -0.1746, -0.0761]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_x가 네트워크를 통과한 값\n",
    "out = net(input_x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.ones(1,10)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.1350626945495605\n"
     ]
    }
   ],
   "source": [
    "# grad 계산 & weight 학습하는 과정\n",
    "import torch.optim as optim\n",
    "\n",
    "# 사용할 optimizer 정의 \n",
    "# 가장 단순한 optimizer : Stochastic Gradient Descent\n",
    "# 이 외에도 Adam, RMSProp... 등등이 있음\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# gradient 초기화\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# output 뽑기\n",
    "out = net(input_x)\n",
    "\n",
    "# loss function 정의\n",
    "criterion = nn.MSELoss()\n",
    "# out, target 사이의 loss 계산\n",
    "loss = criterion(out, target)\n",
    "print(f\"Loss : {loss}\")\n",
    "\n",
    "# loss 역전파 및 그래디언트 계산\n",
    "loss.backward()\n",
    "# weight 업데이트\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9922, grad_fn=<MseLossBackward>)\n",
      "tensor(0.8871, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7851, grad_fn=<MseLossBackward>)\n",
      "tensor(0.6782, grad_fn=<MseLossBackward>)\n",
      "tensor(0.5605, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4343, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3077, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1958, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1123, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0597, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "tensor(8.8952e-05, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4099e-05, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2935e-05, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0069e-05, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2240e-05, grad_fn=<MseLossBackward>)\n",
      "tensor(7.4721e-06, grad_fn=<MseLossBackward>)\n",
      "tensor(4.5652e-06, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7915e-06, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7082e-06, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0461e-06, grad_fn=<MseLossBackward>)\n",
      "tensor(6.4120e-07, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9325e-07, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4133e-07, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4818e-07, grad_fn=<MseLossBackward>)\n",
      "tensor(9.1087e-08, grad_fn=<MseLossBackward>)\n",
      "tensor(5.6010e-08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4448e-08, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1199e-08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3056e-08, grad_fn=<MseLossBackward>)\n",
      "tensor(8.0420e-09, grad_fn=<MseLossBackward>)\n",
      "tensor(4.9560e-09, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0553e-09, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8855e-09, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1661e-09, grad_fn=<MseLossBackward>)\n",
      "tensor(7.2039e-10, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4570e-10, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7662e-10, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7174e-10, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0651e-10, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6030e-11, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1394e-11, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6110e-11, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6029e-11, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0561e-11, grad_fn=<MseLossBackward>)\n",
      "tensor(6.8074e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6374e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1612e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5771e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4112e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1892e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0393e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9021e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7458e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6936e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6477e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5575e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5159e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4460e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4460e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3994e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3411e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3010e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2651e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2651e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2513e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2424e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2513e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1941e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1941e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1756e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1816e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1802e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1802e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1386e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1813e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1813e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1546e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1291e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0395e-12, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9512e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9512e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6527e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6527e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6456e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.3756e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.4040e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.2051e-13, grad_fn=<MseLossBackward>)\n",
      "tensor(9.1305e-13, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(input_x)\n",
    "    loss = criterion(out, target)\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.0843, -0.6223],\n",
      "        [-0.3023, -0.6323],\n",
      "        [ 0.6392, -0.1082]])), ('bias', tensor([ 0.4784, -0.0134, -0.3593]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2110, 0.6396]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치 layer 어떤식으로 진행되는지 테스트\n",
    "fc1 = nn.Linear(2, 3)\n",
    "print(fc1.state_dict())\n",
    "x = torch.rand((1,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0981, -0.4817, -0.2936]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = fc1(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0981, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = F.relu(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

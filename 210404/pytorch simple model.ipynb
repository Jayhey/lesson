{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치의 기본적인 모델 flow 구조\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # 사용할 파라미터를 정의함 (neural net, convnet, lstm, 등등)\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # nn.Linear : 일반적인 뉴럴 네트워크\n",
    "        self.fc1 = nn.Linear(20, 30)\n",
    "        self.fc2 = nn.Linear(30, 40)\n",
    "        self.fc3 = nn.Linear(40, 10)\n",
    "        \n",
    "    # 실제로 값이 통과하는 부분 (연산 작업들은 forward에서 진행)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=20, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=40, bias=True)\n",
       "  (fc3): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 파악\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 1.1906e-01,  1.6910e-01, -9.1122e-02,  3.4714e-02, -1.6478e-01,\n",
       "                        9.9557e-02, -8.0940e-03, -2.0241e-01,  1.5856e-01,  1.8645e-01,\n",
       "                       -1.7109e-01,  1.7156e-01, -1.5311e-01, -1.9251e-02,  4.0418e-02,\n",
       "                        2.5517e-02,  1.1981e-01,  3.6317e-02, -1.7923e-01, -7.3755e-03],\n",
       "                      [ 7.9305e-02,  1.9931e-01, -2.0366e-01,  1.1967e-01, -4.0301e-02,\n",
       "                        2.6372e-02,  1.5090e-01, -1.1800e-02,  1.5825e-01, -8.0637e-03,\n",
       "                        1.5298e-04, -8.1806e-02, -2.1689e-01,  9.1072e-02, -1.5573e-01,\n",
       "                       -2.1730e-01,  8.6066e-03, -1.0245e-01, -1.6658e-01,  1.5077e-01],\n",
       "                      [ 2.1585e-01,  1.6078e-02, -6.4705e-02,  1.1412e-01,  1.8840e-01,\n",
       "                       -2.3172e-02, -1.2647e-01, -1.3991e-01,  9.3556e-02, -8.3779e-02,\n",
       "                        1.3438e-01,  1.4214e-01,  1.8364e-01, -1.3793e-01, -3.8780e-02,\n",
       "                        1.8793e-01,  2.1850e-02,  2.0441e-02,  4.2962e-02, -2.3627e-02],\n",
       "                      [ 6.2894e-02, -8.6259e-02, -1.5890e-01,  5.1608e-02, -2.1453e-01,\n",
       "                        1.2944e-01,  1.0227e-01,  1.0938e-01, -8.0430e-03, -1.4097e-01,\n",
       "                       -7.7491e-02, -1.3937e-01, -2.8786e-03, -1.9073e-01, -1.3565e-01,\n",
       "                        2.0798e-01, -8.8764e-02, -2.6906e-02, -4.1165e-02,  5.4475e-02],\n",
       "                      [ 1.9734e-01,  1.8938e-01,  1.3981e-01,  4.7666e-02, -7.6797e-02,\n",
       "                        7.3653e-02,  2.0120e-01,  1.0006e-01,  1.0063e-01,  1.8348e-02,\n",
       "                       -3.7281e-02,  2.0852e-01,  2.5089e-02,  3.2909e-02, -1.2483e-02,\n",
       "                        1.5304e-01, -1.7409e-01,  1.9808e-02, -1.2576e-01, -7.1628e-03],\n",
       "                      [ 1.4869e-02,  2.6970e-02, -1.8168e-01,  1.3318e-01,  1.4591e-01,\n",
       "                        1.5549e-01,  1.2404e-01, -3.3480e-02, -4.3640e-02, -1.6990e-01,\n",
       "                        1.0476e-01, -1.6307e-01, -2.1107e-01, -9.6651e-02, -1.1901e-02,\n",
       "                        1.6959e-01,  8.0712e-02,  1.9390e-01,  1.9851e-01, -2.1156e-01],\n",
       "                      [ 7.3657e-02,  2.2233e-02,  6.5142e-02,  1.4825e-01,  5.4192e-03,\n",
       "                       -7.8099e-02,  1.7383e-01, -1.6140e-01, -1.0370e-01, -9.5957e-02,\n",
       "                        1.9592e-01, -2.4332e-02, -3.5641e-03,  1.9738e-01, -1.3630e-01,\n",
       "                        3.4622e-02, -5.7101e-02, -6.7282e-02,  6.9623e-02,  1.5266e-01],\n",
       "                      [ 1.0866e-01, -6.4491e-02,  4.9847e-02,  1.3173e-01, -1.7027e-01,\n",
       "                       -1.9399e-01,  1.9743e-01, -1.1756e-01, -5.8145e-02, -1.8353e-01,\n",
       "                       -3.4535e-02,  2.1548e-02, -1.7371e-01,  8.3148e-02, -7.7815e-02,\n",
       "                       -1.6843e-01,  1.6714e-01,  2.4963e-03, -1.2733e-02, -7.1345e-02],\n",
       "                      [ 1.8929e-01,  4.9157e-02,  1.5135e-01, -1.5449e-02, -1.0635e-01,\n",
       "                       -1.1450e-01, -1.8263e-01,  1.1317e-01, -1.8914e-01,  1.1175e-01,\n",
       "                       -1.8973e-01,  1.1710e-01, -3.3230e-02,  2.1362e-02, -1.9745e-01,\n",
       "                        1.2564e-01,  2.1908e-01,  1.0227e-01, -1.2872e-01,  8.0591e-03],\n",
       "                      [-2.1389e-02,  8.0928e-02, -1.2255e-01, -2.1453e-01,  1.9929e-02,\n",
       "                       -8.5827e-02,  1.7805e-01, -2.5855e-02,  1.9332e-01, -1.6771e-02,\n",
       "                        1.4433e-01, -7.6731e-02,  9.4869e-02,  9.3746e-02, -1.2101e-01,\n",
       "                       -8.8390e-02, -1.8896e-01, -7.0966e-02, -6.8444e-02,  1.5095e-01],\n",
       "                      [-1.7246e-01,  1.0065e-01, -8.8207e-02, -7.2062e-03, -1.4484e-01,\n",
       "                       -8.8276e-02,  8.3173e-02, -4.3565e-02,  7.9016e-02,  1.4448e-02,\n",
       "                        8.7198e-02, -6.5814e-02,  1.5840e-01,  1.7914e-01,  1.2433e-01,\n",
       "                        2.6454e-03,  6.6054e-03, -2.7357e-02,  8.2861e-02, -2.0069e-01],\n",
       "                      [ 1.5995e-01,  1.7466e-02, -5.1056e-03,  2.4868e-02,  1.8431e-01,\n",
       "                       -1.7699e-01,  2.1826e-01, -9.6270e-02,  1.1865e-01,  1.9113e-01,\n",
       "                       -5.3435e-02, -1.2973e-01,  1.0528e-01, -6.7939e-02,  5.9818e-02,\n",
       "                       -1.0346e-01, -9.6724e-02, -1.3920e-01, -8.7878e-02, -4.6044e-02],\n",
       "                      [-5.5376e-02,  1.9508e-01,  1.3484e-01,  1.0958e-01, -9.3996e-02,\n",
       "                        1.8639e-01,  2.8187e-02,  1.1441e-01, -4.5284e-02, -4.8660e-02,\n",
       "                       -1.7280e-01,  1.9090e-01, -1.4444e-01,  6.5591e-02, -6.2290e-02,\n",
       "                       -1.7778e-01, -1.9604e-01, -5.6430e-02,  5.1776e-02,  1.5465e-01],\n",
       "                      [-1.0932e-01, -1.2435e-01, -6.1159e-02, -1.1395e-01,  2.0621e-01,\n",
       "                       -1.0352e-01, -1.3180e-02,  5.7899e-02, -1.4701e-01, -1.8776e-01,\n",
       "                       -1.1818e-01, -1.9140e-01,  1.8676e-01, -1.1004e-01,  1.4363e-02,\n",
       "                        6.9259e-03, -3.3036e-02, -1.9397e-01, -1.1633e-01,  1.1740e-01],\n",
       "                      [ 2.0881e-02,  1.4618e-01,  9.0730e-03,  1.4878e-01,  6.3453e-03,\n",
       "                       -3.7734e-02,  1.8428e-01, -1.2612e-01,  8.9500e-02, -5.8758e-02,\n",
       "                       -8.2728e-02, -2.4890e-02, -1.3635e-01,  1.1129e-01,  1.3674e-01,\n",
       "                       -1.9753e-01, -3.9025e-02, -1.5764e-01,  8.8821e-03,  1.5701e-01],\n",
       "                      [-1.4263e-01, -3.6082e-02, -2.7505e-02, -2.1081e-01,  9.6327e-02,\n",
       "                       -6.2500e-02, -1.5302e-01,  1.1334e-02,  1.2477e-01,  1.9959e-01,\n",
       "                       -2.0967e-03, -1.5710e-01, -7.9145e-02, -1.3894e-01, -1.0568e-01,\n",
       "                       -1.6037e-01, -2.9987e-02,  9.3074e-02,  3.0814e-02, -9.8017e-02],\n",
       "                      [-1.0195e-01,  6.8973e-02, -2.7265e-03, -2.0907e-01, -1.6938e-01,\n",
       "                        6.2527e-02,  1.3699e-01,  5.1830e-02, -1.1935e-01, -9.4943e-03,\n",
       "                       -1.1781e-01, -8.8042e-02,  1.5817e-01, -4.5217e-02, -1.5673e-01,\n",
       "                        1.6593e-01, -2.5987e-02, -1.1060e-01,  2.7192e-02, -2.0929e-01],\n",
       "                      [-1.5905e-01,  9.8791e-02, -2.6140e-02, -7.2201e-03, -1.3810e-01,\n",
       "                        7.9631e-02,  1.0069e-01, -5.3404e-02, -2.2288e-01, -1.2881e-01,\n",
       "                       -1.3596e-01,  1.8726e-01,  1.0305e-01, -1.2218e-01,  1.2743e-02,\n",
       "                        1.9404e-02, -6.4582e-02,  8.0088e-02, -1.9386e-01,  6.4047e-02],\n",
       "                      [ 7.6423e-02, -2.0009e-01, -4.7608e-02, -1.3537e-01, -1.9646e-01,\n",
       "                        6.1364e-02,  2.1866e-01, -1.5429e-01, -1.5820e-01,  1.2951e-01,\n",
       "                        1.8157e-01,  2.1154e-01,  1.7227e-01, -7.0408e-02, -5.6620e-02,\n",
       "                       -3.6179e-02, -1.7519e-01,  1.7117e-01,  1.9614e-02,  1.2167e-01],\n",
       "                      [-1.0366e-01, -1.0997e-01,  2.2126e-01,  3.8885e-02,  1.4056e-01,\n",
       "                        1.5994e-01,  2.5914e-02,  1.3604e-01, -1.6390e-01, -1.8284e-01,\n",
       "                        1.8741e-01,  1.4213e-01, -3.4661e-02,  5.6760e-02,  8.4544e-02,\n",
       "                        1.0554e-01, -1.1876e-02,  7.6828e-02, -1.6691e-01,  1.1132e-01],\n",
       "                      [-1.8340e-02,  6.9412e-02,  2.0274e-02,  1.1848e-01,  5.0442e-02,\n",
       "                        1.4801e-01, -7.8172e-02, -2.0643e-01,  1.0097e-01, -8.7218e-02,\n",
       "                        1.2828e-01, -1.0596e-01,  1.2825e-01,  9.5205e-02,  1.3647e-01,\n",
       "                       -4.4336e-02, -1.2425e-01,  2.1201e-01, -4.0213e-02,  8.1895e-02],\n",
       "                      [ 4.0497e-02, -1.3144e-01,  2.1871e-02,  2.8812e-02, -1.2567e-01,\n",
       "                       -5.6997e-02, -1.0991e-01, -5.1326e-02, -1.3277e-01, -2.1077e-01,\n",
       "                        1.4245e-01, -1.4890e-01,  9.1891e-02, -2.9867e-02,  1.0629e-01,\n",
       "                        8.0956e-02,  1.6942e-01, -7.3047e-02,  3.5985e-02, -1.8998e-01],\n",
       "                      [ 1.2285e-01,  2.1855e-01, -1.1591e-01,  1.5662e-01,  3.6767e-03,\n",
       "                        9.6548e-02,  1.1391e-01, -1.8036e-01,  1.7529e-01, -4.4804e-02,\n",
       "                       -1.4733e-01,  7.8683e-02, -1.3571e-01, -8.8318e-02, -1.3402e-01,\n",
       "                        5.0465e-02,  4.3190e-02, -7.3398e-03,  1.5872e-01,  1.5936e-01],\n",
       "                      [ 8.1554e-02, -1.4556e-01,  4.0925e-02, -2.0604e-02,  2.1722e-01,\n",
       "                       -1.4244e-01,  5.6603e-02,  1.7262e-01,  9.4455e-03,  5.5994e-02,\n",
       "                        1.1018e-01, -1.9532e-01, -1.0083e-01, -1.2940e-01, -8.1439e-02,\n",
       "                        1.3773e-01,  4.7853e-02, -2.8433e-02, -1.5829e-01, -1.9400e-01],\n",
       "                      [-1.6061e-01,  5.9759e-03, -1.3724e-01, -1.9800e-03,  1.4298e-01,\n",
       "                       -1.9868e-01,  1.9090e-01, -1.9026e-01,  6.6949e-02, -1.2542e-01,\n",
       "                       -8.5314e-02, -1.3512e-01,  1.8700e-01, -6.4444e-02, -1.4579e-01,\n",
       "                        1.8823e-03, -2.0908e-01, -3.8105e-02, -2.1096e-01,  1.6763e-01],\n",
       "                      [-2.0269e-01,  1.9962e-01,  3.8615e-02, -1.3983e-01, -7.8040e-02,\n",
       "                       -1.8094e-03,  2.0654e-01, -1.7295e-02, -1.6669e-01, -1.8707e-01,\n",
       "                        4.5692e-02, -2.1933e-01, -1.2565e-01,  2.1764e-01, -7.6613e-02,\n",
       "                        1.3158e-01, -1.9050e-01,  1.1180e-01, -3.1415e-02,  1.3945e-01],\n",
       "                      [-4.8679e-02, -1.3811e-01,  1.7753e-01, -7.3314e-02,  1.4064e-01,\n",
       "                       -4.5030e-02, -2.1792e-01,  2.5361e-02, -1.7931e-01, -1.5011e-01,\n",
       "                        2.8787e-02, -1.9684e-01, -3.1308e-02, -2.2303e-02, -1.4925e-01,\n",
       "                        1.3367e-01,  3.7726e-02, -6.5962e-02, -1.9081e-01,  1.7987e-02],\n",
       "                      [-1.8000e-01,  7.4357e-02,  1.9456e-01,  5.5693e-02,  2.4137e-03,\n",
       "                        1.7492e-01, -1.2619e-01,  1.3217e-02,  3.9242e-02, -5.4574e-02,\n",
       "                       -3.7926e-02, -1.6152e-01,  1.5110e-01, -5.6364e-04,  7.7009e-03,\n",
       "                        2.3672e-02,  1.0267e-01,  1.8694e-02, -1.4930e-01, -6.8125e-02],\n",
       "                      [ 2.0577e-01,  3.3459e-03,  1.1962e-01, -5.0914e-02,  1.2157e-01,\n",
       "                       -6.3627e-02, -9.9154e-02,  1.8822e-01, -2.8313e-02,  1.4411e-01,\n",
       "                       -3.8551e-02,  2.2305e-01, -1.7133e-02,  1.7488e-01, -6.9397e-02,\n",
       "                        3.7612e-02, -1.2680e-01, -1.0476e-01,  2.0434e-02, -6.9276e-02],\n",
       "                      [-1.9500e-01,  5.4559e-03, -1.2746e-01, -1.4189e-02,  8.4297e-02,\n",
       "                        3.1512e-03, -1.4027e-01, -1.3407e-01, -2.7031e-02, -5.4149e-02,\n",
       "                       -2.1634e-01, -1.1545e-01, -1.6927e-01,  1.2892e-01,  4.5133e-02,\n",
       "                        1.2517e-01, -5.0857e-02, -8.2975e-02,  2.0633e-01,  3.6970e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.1816, -0.0969,  0.2223,  0.1786,  0.1296,  0.0970,  0.0047, -0.1350,\n",
       "                      -0.1088,  0.0805, -0.1925,  0.0118,  0.0785, -0.1337,  0.1265,  0.1483,\n",
       "                      -0.1716, -0.0689,  0.1027,  0.0670,  0.2099,  0.1894, -0.2086,  0.1779,\n",
       "                      -0.1007,  0.0400, -0.1086, -0.1343,  0.1104, -0.0955])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0102, -0.0803, -0.0089,  ..., -0.0041, -0.1581, -0.1317],\n",
       "                      [-0.0232,  0.0997,  0.1137,  ...,  0.0316, -0.0415, -0.0553],\n",
       "                      [-0.0119, -0.0239,  0.0526,  ...,  0.1622, -0.0735, -0.1817],\n",
       "                      ...,\n",
       "                      [ 0.0027, -0.1081,  0.1526,  ...,  0.0145, -0.1086, -0.0907],\n",
       "                      [-0.1444, -0.1746,  0.0577,  ..., -0.0675,  0.0071, -0.0662],\n",
       "                      [-0.0555,  0.1124, -0.0752,  ..., -0.1235,  0.0899,  0.1683]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0898,  0.1210,  0.0588, -0.0465,  0.1439,  0.1456, -0.0792,  0.0222,\n",
       "                       0.0054,  0.1769, -0.1356, -0.1598, -0.0940,  0.0002, -0.0535, -0.0572,\n",
       "                      -0.0406, -0.0542,  0.0367,  0.0170, -0.0645,  0.0437,  0.0379, -0.1299,\n",
       "                       0.1802, -0.1062,  0.0918,  0.1430, -0.1199, -0.1310, -0.0977, -0.1375,\n",
       "                      -0.1744,  0.0711, -0.0688, -0.0040, -0.0077, -0.1752, -0.0274, -0.0627])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-6.7985e-03,  7.3027e-02,  1.0535e-01,  5.0091e-02,  1.4412e-02,\n",
       "                       -1.3118e-01, -6.1992e-02, -4.5761e-02, -1.1670e-01, -1.5380e-01,\n",
       "                        3.3433e-02,  1.6098e-02,  4.9644e-02,  6.4295e-02, -1.0773e-01,\n",
       "                       -4.1630e-02, -1.5263e-01, -1.1862e-01,  1.5629e-01,  4.6127e-02,\n",
       "                       -1.3078e-01, -7.5769e-02,  1.1199e-01, -1.1510e-01,  9.2873e-02,\n",
       "                        7.9715e-02, -4.6318e-02, -1.0781e-01, -8.9902e-02,  1.4025e-01,\n",
       "                       -5.4429e-02,  6.1659e-02,  6.4388e-02, -1.4430e-01,  2.3449e-02,\n",
       "                        4.2302e-02, -9.4872e-02, -3.5463e-02, -9.8597e-02, -9.4735e-02],\n",
       "                      [ 7.6468e-02, -3.7642e-03,  9.4443e-02,  1.2896e-01,  1.2850e-01,\n",
       "                       -1.7779e-02, -1.6392e-02, -1.5447e-01,  6.6742e-02, -5.1711e-02,\n",
       "                       -7.4713e-02, -1.5924e-02, -2.8889e-04,  4.9098e-02, -4.1182e-02,\n",
       "                       -1.5622e-01,  6.7898e-02, -8.4024e-02, -9.1153e-02,  1.1539e-01,\n",
       "                        1.1078e-01,  8.4297e-02, -7.4560e-02, -9.9325e-02, -1.1986e-01,\n",
       "                        5.4439e-03,  1.0935e-01,  4.6835e-02, -1.2958e-01, -1.1631e-01,\n",
       "                       -9.3357e-02, -2.5990e-02,  1.1406e-01,  3.9592e-02, -1.4312e-01,\n",
       "                       -1.5082e-02, -1.0164e-01,  1.6653e-02, -9.4511e-02,  5.4138e-02],\n",
       "                      [ 1.4124e-02, -2.8956e-02,  1.2919e-01,  1.0619e-01,  8.2000e-02,\n",
       "                        5.2066e-02, -2.9241e-02, -4.3417e-02,  1.4836e-01, -8.0104e-02,\n",
       "                        1.1534e-02, -1.2758e-01,  1.2844e-02,  8.9200e-02,  1.2569e-01,\n",
       "                        2.3702e-02,  1.0488e-01, -1.3502e-01,  7.9816e-02, -6.0212e-02,\n",
       "                        2.8894e-02, -1.3122e-01,  9.6979e-02,  1.5587e-01,  3.2991e-02,\n",
       "                        1.1033e-01,  6.6261e-02, -2.6468e-02, -1.1281e-01, -1.5567e-01,\n",
       "                        1.2068e-01,  4.0600e-02,  1.3862e-01,  5.7178e-02, -6.2641e-02,\n",
       "                       -5.6993e-03, -9.2342e-02,  1.4244e-01,  6.1068e-02, -5.6805e-02],\n",
       "                      [-1.4427e-01, -4.5760e-03,  1.1605e-01, -1.0076e-01,  6.4809e-02,\n",
       "                        7.5176e-02,  1.0077e-01, -6.6014e-02,  3.5748e-02, -9.6718e-02,\n",
       "                       -9.2497e-02,  6.8034e-02, -7.2332e-02,  1.5219e-01, -1.5191e-01,\n",
       "                       -1.3187e-01,  8.4760e-02, -1.4822e-01,  1.4883e-01, -1.0269e-01,\n",
       "                        1.2965e-01, -8.5414e-02,  1.1976e-01,  6.6822e-02, -4.8292e-02,\n",
       "                       -3.8877e-02,  4.8753e-02, -6.0481e-02,  5.1410e-02, -5.7309e-02,\n",
       "                        1.0093e-01, -2.2454e-02, -2.0615e-02,  2.9331e-02, -1.3888e-01,\n",
       "                       -2.4828e-02, -7.2755e-02,  1.4905e-01,  7.5509e-02, -1.4393e-01],\n",
       "                      [-1.0943e-01,  1.5166e-01, -3.0658e-02, -7.0964e-02, -9.3943e-02,\n",
       "                        4.5677e-03, -2.0094e-02,  6.1570e-02,  1.3714e-01, -1.1051e-01,\n",
       "                        1.4116e-01,  1.3332e-01, -1.0469e-01, -1.3330e-01,  1.4488e-01,\n",
       "                        1.3818e-01, -2.5156e-02,  1.2052e-01,  3.6363e-02, -1.1360e-01,\n",
       "                        1.2479e-01, -1.4516e-01,  1.8183e-02, -1.1715e-01, -1.4681e-01,\n",
       "                       -1.0828e-01,  1.2863e-01, -7.8708e-02,  5.6413e-02, -5.8586e-02,\n",
       "                       -5.6317e-02,  1.5579e-02, -1.3451e-01, -1.2910e-01, -9.4113e-02,\n",
       "                        1.2309e-01, -3.2942e-02,  4.3606e-02,  1.4135e-04, -5.5557e-03],\n",
       "                      [-1.0070e-01, -7.3009e-02,  1.3624e-01, -3.8263e-02, -9.5155e-02,\n",
       "                        5.0779e-02,  8.3013e-02,  3.6010e-03,  1.1812e-01,  1.2199e-01,\n",
       "                       -1.4092e-01, -9.9839e-02,  1.1345e-01, -1.2572e-01, -8.5053e-02,\n",
       "                        1.0750e-02,  6.3445e-02, -1.1826e-01,  6.0308e-02,  3.8610e-02,\n",
       "                       -1.0700e-01, -1.3121e-01,  1.5636e-01, -1.4201e-01,  1.3820e-01,\n",
       "                        7.4399e-02,  1.0850e-01, -1.9298e-02,  1.2318e-01,  1.4372e-01,\n",
       "                       -2.0121e-02,  3.9149e-02,  7.9279e-02,  6.5088e-02, -3.2785e-02,\n",
       "                        1.5655e-01, -3.8731e-02,  5.1075e-02, -1.3275e-01, -1.3490e-01],\n",
       "                      [ 1.0092e-01, -5.0317e-03, -1.3983e-01,  7.5622e-02,  1.3565e-01,\n",
       "                       -6.4873e-02,  7.0401e-02, -9.2044e-05,  1.6892e-02,  1.6695e-02,\n",
       "                        1.2656e-01,  2.9899e-02,  5.0031e-02, -6.8675e-02,  1.4943e-02,\n",
       "                        1.4483e-01, -1.0983e-01,  1.3150e-01, -6.3244e-02,  1.1031e-01,\n",
       "                        1.0544e-01, -1.4537e-01, -8.7605e-02,  6.7342e-02,  8.9857e-03,\n",
       "                       -5.9171e-02,  7.4941e-02, -1.3215e-01,  4.5456e-02, -1.1340e-01,\n",
       "                       -2.7585e-02,  6.7631e-02,  3.2775e-02, -1.3240e-01, -1.0107e-01,\n",
       "                        1.3461e-01,  1.4105e-01, -8.1049e-02, -5.4567e-02,  8.2003e-02],\n",
       "                      [ 1.5671e-01, -4.7566e-02,  1.4557e-01,  4.0392e-02,  1.0637e-01,\n",
       "                       -1.0043e-02,  1.3628e-01, -1.2247e-01,  2.6448e-02, -1.7203e-02,\n",
       "                       -2.1817e-02, -8.5215e-02, -9.5388e-02, -5.0717e-02,  5.4924e-02,\n",
       "                        2.1647e-02,  5.6248e-02, -6.1979e-02,  6.7185e-02,  8.0485e-02,\n",
       "                        3.5995e-02, -3.6401e-02,  1.2045e-01, -1.1257e-01,  1.1609e-01,\n",
       "                       -9.7484e-02, -1.1274e-01, -9.2352e-02,  1.3318e-01, -7.8037e-02,\n",
       "                        7.6976e-02, -5.9466e-02,  4.7141e-02,  1.0902e-01, -2.5165e-02,\n",
       "                       -1.4866e-01,  5.0136e-02,  1.3210e-01, -1.1375e-01,  4.4272e-02],\n",
       "                      [ 7.8616e-02,  4.5558e-02,  1.4842e-01, -6.0510e-02, -1.3348e-01,\n",
       "                        1.5523e-02,  2.0085e-02,  9.0543e-03,  3.7312e-02, -1.3751e-01,\n",
       "                        1.4121e-01,  9.8309e-02, -8.6845e-03, -9.1368e-02, -1.4707e-01,\n",
       "                        8.0754e-02, -3.0710e-03, -1.1506e-01,  1.4331e-01,  6.6377e-02,\n",
       "                       -1.3054e-02, -1.3101e-01,  4.9988e-02, -2.2853e-02,  3.7039e-02,\n",
       "                       -3.8030e-02,  7.9486e-02, -2.6344e-02,  1.1684e-01,  8.2015e-02,\n",
       "                        2.6689e-02,  3.9158e-02, -1.1037e-01, -1.4430e-01,  5.3266e-03,\n",
       "                       -1.2599e-01, -4.4889e-02, -1.3388e-01,  9.1989e-02, -1.3572e-01],\n",
       "                      [-9.8489e-02, -1.0038e-01,  1.3010e-01,  1.1632e-01,  4.0627e-02,\n",
       "                        1.3653e-01, -1.8452e-02, -1.3162e-01, -4.0531e-02, -1.1327e-01,\n",
       "                        1.1895e-01, -8.6611e-02, -1.4868e-01, -1.5043e-02,  6.5526e-02,\n",
       "                       -1.7824e-02,  1.4054e-01, -1.3252e-01, -2.8405e-03, -3.0339e-02,\n",
       "                        1.7534e-02, -7.4449e-02, -3.6272e-02,  1.5004e-01,  6.4484e-02,\n",
       "                       -3.6466e-02, -1.3312e-01,  4.1074e-02, -6.4091e-02, -2.7300e-02,\n",
       "                        1.5137e-01,  9.8046e-02,  1.2355e-01, -4.0211e-02, -4.9503e-02,\n",
       "                        8.3816e-02,  4.3172e-02,  1.4370e-01,  5.1788e-02, -5.8270e-02]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.1118,  0.1323, -0.1023, -0.1492,  0.0507, -0.0863, -0.0950, -0.0559,\n",
       "                      -0.0461, -0.0740]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 직접 보기\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 30])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension size check하는 방법 (굉장히 많이 씀)\n",
    "net.state_dict()['fc2.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0454,  0.4530,  0.4766,  1.0096,  1.2725, -0.2080, -1.8094, -0.3082,\n",
       "         -0.3205,  0.8400,  1.6714, -0.9516, -1.2532, -0.6099,  0.1904, -0.5120,\n",
       "         -0.4534, -0.9616, -0.4912,  1.2027]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 앞의 숫자는 batch size\n",
    "\n",
    "input_x = torch.randn(1, 20)\n",
    "input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1866,  0.0404, -0.1266, -0.1912,  0.0623,  0.0052, -0.1457, -0.0735,\n",
       "         -0.0603, -0.1852]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_x가 네트워크를 통과한 값\n",
    "out = net(input_x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.ones(1,10)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.1879945993423462\n"
     ]
    }
   ],
   "source": [
    "# grad 계산 & weight 학습하는 과정\n",
    "import torch.optim as optim\n",
    "\n",
    "# 사용할 optimizer 정의 \n",
    "# 가장 단순한 optimizer : Stochastic Gradient Descent\n",
    "# 이 외에도 Adam, RMSProp... 등등이 있음\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# gradient 초기화\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# output 뽑기\n",
    "out = net(input_x)\n",
    "\n",
    "# loss function 정의\n",
    "criterion = nn.MSELoss()\n",
    "# out, target 사이의 loss 계산\n",
    "loss = criterion(out, target)\n",
    "print(f\"Loss : {loss}\")\n",
    "\n",
    "# loss 역전파 및 그래디언트 계산\n",
    "loss.backward()\n",
    "# weight 업데이트\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1880, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(input_x)\n",
    "    loss = criterion(out, target)\n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 layer 어떤식으로 진행되는지 테스트\n",
    "fc1 = nn.Linear(2, 3)\n",
    "print(fc1.state_dict())\n",
    "x = torch.rand((1,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc1(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 페이지 내에 있는 제목과 링크를 한 번에 긁어오는 함수 생성\n",
    "def get_paper_links(page_url):\n",
    "    page = requests.get(page_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    doc_sum = soup.find_all('a', class_='docsum-title', href=True)\n",
    "    \n",
    "    titles = []\n",
    "    links = []\n",
    "    for doc in doc_sum:\n",
    "        titles.append(doc.text.strip())\n",
    "        links.append('https://pubmed.ncbi.nlm.nih.gov'+doc['href'])\n",
    "    \n",
    "    return titles, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모든 논문들의 제목과 링크 긁어오기\n",
    "\n",
    "titles = []\n",
    "links = [] \n",
    "for i in range(1, 44):\n",
    "    \n",
    "    # f string\n",
    "    url = f'https://pubmed.ncbi.nlm.nih.gov/?term=korean%20journal%20of%20orthodontics&page={i}'\n",
    "    \n",
    "    # 위에서 생성한 함수 사용\n",
    "    page_titles, page_links = get_paper_links(url)\n",
    "    \n",
    "    titles += page_titles\n",
    "    links += page_links\n",
    "    \n",
    "    print(f'PAGE {i}/43 complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles, links 하나의 칼럼으로 가지는 데이터프레임 생성\n",
    "df = pd.DataFrame(data={'titles':titles, 'links':links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_doc(url):\n",
    "    # url Html 구조 긁어오기\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # title 긁어오기\n",
    "    article_page = soup.find('div', class_='article-page')\n",
    "    article_details = article_page.find('main', class_='article-details')\n",
    "    full_view = article_details.find('div', class_='full-view')\n",
    "    title = full_view.find('h1', class_='heading-title')\n",
    "    title = title.get_text(strip=True)\n",
    "    \n",
    "    # abstract 긁어오기\n",
    "    abstract = soup.find('div', class_='abstract-content selected')\n",
    "    \n",
    "    if abstract:\n",
    "        contents = abstract.find_all('p')\n",
    "        abstracts = []\n",
    "        for content in contents:\n",
    "            all_txt = content.get_text(strip=True)\n",
    "            abstracts.append(all_txt)\n",
    "           \n",
    "        abstracts =' '.join(abstracts)\n",
    "    else:\n",
    "        abstracts = 'Error'\n",
    "         \n",
    "    # meta_name 긁어오기\n",
    "    div_authors = soup.find('div', class_='authors')\n",
    "    if div_authors:\n",
    "        authors = div_authors.find_all('a', class_='full-name')\n",
    "    \n",
    "        meta_name = [] \n",
    "\n",
    "        for author in authors:\n",
    "            tmp = author.get_text(strip=True)\n",
    "            meta_name.append(tmp)\n",
    "    \n",
    "        meta_name = ','.join(meta_name)\n",
    "    \n",
    "    else:\n",
    "        meta_name = 'Error'\n",
    "   \n",
    "    # meta_keywords 긁어오기\n",
    "    try:\n",
    "        div_abstract = soup.find('div', class_='abstract')   \n",
    "        div_abstract.find('div', class_='abstract-content selected').decompose()\n",
    "\n",
    "        keywords = div_abstract.find('p').get_text(strip=True)\n",
    "        keywords = keywords.split(':')[1]\n",
    "        meta_keywords = keywords = keywords.split('; ')\n",
    "        meta_keywords = ','.join(meta_keywords)\n",
    "    except:\n",
    "        meta_keywords = 'Error'\n",
    "\n",
    "    return title, abstracts, meta_name, meta_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "abstracts = []\n",
    "meta_names = []\n",
    "meta_keywords = []\n",
    "\n",
    "list_links = list(df.links)\n",
    "\n",
    "for i, url in enumerate(list_links):\n",
    "    print(f\"{i+1} / {len(list_links)} COMPLETE\")\n",
    "    _, abstract, meta_name, meta_keyword = crawling_doc(url)\n",
    "    \n",
    "    abstracts.append(abstract)\n",
    "    meta_names.append(meta_name)\n",
    "    meta_keywords.append(meta_keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 생성\n",
    "# 첫 번째 방법 : 새로 만들기\n",
    "result_df = pd.DataFrame(data={'titles':titles,\n",
    "                               'links':links,\n",
    "                               'abstracts':abstracts,\n",
    "                               'meta_names':meta_names,\n",
    "                               'meta_keywords':meta_keywords})\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /Users/geoffrey/jupyter/lesson/201227/test_folder/crawling_result.csv\n",
    "result_df.to_csv(\"./test_folder/crawling_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.read_csv(\"crawling_result.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스의 구조 \n",
    "# iloc, loc 차이점 반드시 숙지\n",
    "# iloc : 행 기준 인덱싱\n",
    "# loc : index 기준 인덱싱 -> 판다스의 구조 알고 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = {}\n",
    "tmp_dict['idx'] = [1, 3, 5, 7, 9]\n",
    "tmp_dict['column'] = ['a', 'p', 'p', 'l', 'e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(tmp_dict)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_df.iloc[0])\n",
    "print(tmp_df.loc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = tmp_df.set_index('idx')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df.loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 진행 사항\n",
    "# 1. 필요 없는 단어 제거\n",
    "# 2. pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective: , Methods:, Results:, Conclusions:\n",
    "test = result_df.abstracts[2]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = test.split(' ')\n",
    "test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try, except로 : 기준으로 나눠보기\n",
    "# 완성시켜보기\n",
    "for x in test_split:\n",
    "    try:\n",
    "        tmp = x.split(':')\n",
    "        tmp = x[1]\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 단어들이 해당 문자열에 포함되어 있는지 확인\n",
    "check_words = ['Objective:', 'Methods:', 'Results:', 'Conclusions:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_token(token):\n",
    "    for word in check_words:\n",
    "        if word in token:\n",
    "            return token.split(':')[1]\n",
    "        else:\n",
    "            continue\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = 'Results:IMPORTANT!'\n",
    "check_token(test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tokens = []\n",
    "for token in test_split:\n",
    "    result_tokens.append(check_token(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *map function\n",
    "# [A, B, C, D, ..., N]\n",
    "# 리스트의 엘리먼트에 원하는 함수를 적용\n",
    "\n",
    "# 기존 방법\n",
    "result_tokens = []\n",
    "for token in test_split:\n",
    "    result_tokens.append(check_token(token))\n",
    "\n",
    "# map function 활용\n",
    "result_tokens = list(map(lambda x: check_token(x), test_split))\n",
    "\n",
    "# 받는 인자가 하나인 경우 그냥 이런식으로 표현해도 됨!\n",
    "# list(map(check_token, test_split))\n",
    "\n",
    "# 예제 하나 더 : 모든 리스트 내부 엘리먼트들을 문자열 형태로 변환하기\n",
    "# test = [1, 2, 3, 4, 5]\n",
    "# list(map(str, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stop words 목록 확인\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
